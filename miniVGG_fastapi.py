from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional, Dict
from imutils import paths
from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold
from sklearn.metrics import classification_report
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.models import load_model
from sklearn.preprocessing import LabelBinarizer

from toolbox.tf.nn.conv.miniVGGNet import MiniVGGNet
from toolbox.loading.simple_dataset_loader import SimpleDatasetLoader
from toolbox.preprocessing.simple_preprocessor import SimplePreprocessor
from toolbox.utils.compare_directories import _isEqualSubDirs
from config import PKL_PATH, EPOCHS

import numpy as np
import os

"""
Train Curl:
curl -X POST "http://localhost:8001/train" -H "Content-Type: application/json" -d '{"taskId": "TR-123456-20240502171300", "trainOnly": false,"dataset":"/app/train/animals"}'
Predict Curl:
curl -X POST "http://localhost:8001/predict" -H "Content-Type: application/json" -d '{"trainTaskId": "TR-123456-20240502171300", "trainDataset":"/app/train/animals", "predictDataset":"/app/predict/animals"}'
"""


app = FastAPI()

class MiniVGGPredictResponse(BaseModel):
    accuracy: float
    classificationReport: str
    predictions: Dict[str, str]

class MiniVGGPredictRequest(BaseModel):
    trainId: int
    trainDataset: str
    predictDataset: str
    weightsFile: str


class MiniVGGTrainRequest(BaseModel):
    # this is a value auto-generated by the master node
    # It represents the ID of the current training job
    taskId: int 
    # This value will determite if a testing set is needed to be set aside 
    # for scoring. By default it is False, which means a test set should 
    # be set aside for scoring
    trainOnly: Optional[bool] = False
    # This is a string that represents the path to the training data
    dataset: str

class MiniVGGTrainResponse(BaseModel):
    # This is the same taskId that was sent to this container by the master node
    taskId: int
    # This is the path to which the pickled model is saved
    modelPath: str
    # This is the score representing the model's performance
    accuracy: float
    # This is a long string representing the classification report 
    # of the resulting model
    classificationReport: str

@app.post("/predict")
def predict(request: MiniVGGPredictRequest) -> MiniVGGPredictResponse:
    print("[INFO] Received MiniVGG Predict Request")
    # initialize the local binary patterns descriptor along with the data and label lists
    trainDataset = request.trainDataset
    predictDataset = request.predictDataset
    trainTaskId = request.trainId
    weightsFile = request.weightsFile

    isEqualSubDirs = _isEqualSubDirs(trainDataset, predictDataset)
    isDirOfImages = len(next(os.walk(predictDataset))[1]) == 0
    if not isEqualSubDirs and not isDirOfImages:
        return {"error": "Directory mismatch - incorrect number of subdirectories"}


    imagePaths = list(paths.list_images(predictDataset))
    preprocessor = SimplePreprocessor(128, 128)
    loader = SimpleDatasetLoader(preprocessors=[ preprocessor ])
    model = load_model(weightsFile)
    (images, imageLabels, imageNames) = loader.load(imagePaths)
    images = images.astype("float") / 255.0
    lb = LabelBinarizer()
    binarizedLabels = lb.fit_transform(imageLabels)
    predictions = model.predict(images, batch_size=32)
    report = None
    accuracy = None
    if isEqualSubDirs: # has same structure as training set, meaning, the images are labeled
        report = classification_report(
            binarizedLabels.argmax(axis=1), 
            predictions.argmax(axis=1), 
            target_names=np.unique(imageLabels)
        )
        accuracy = model.evaluate(images, binarizedLabels)[1]

    print("[INFO] Prediction Complete. Preparing Response")
    response = MiniVGGPredictResponse(
        accuracy=accuracy,
        classificationReport=report,
        predictions=dict(zip(imageNames, lb.inverse_transform(predictions).tolist()))
    )
    return response

@app.post("/train")
def train(request: MiniVGGTrainRequest) -> MiniVGGTrainResponse:
    print("[INFO] Received MiniVGG Training Request")
    # initialize the local binary patterns descriptor along with the data and label lists
    dataset = request.dataset
    print(f"[INFO] Dataset Received For Training: {dataset.split(os.path.sep)[-1]}")
    taskId = request.taskId
    trainOnly = request.trainOnly

    imagePaths = list(paths.list_images(dataset))
    preprocessor = SimplePreprocessor(128, 128)
    loader = SimpleDatasetLoader(preprocessors=[ preprocessor ])
    (images, imageLabels, _) = loader.load(imagePaths)

    images = images.astype("float") / 255.0
    lb = LabelBinarizer()
    labels = lb.fit_transform(imageLabels)

    print("[INFO] Preparing Training Data")
    if trainOnly:
        trainImages = images
        trainLabels = labels
        # no need to set aside a test set
        testImages = np.array([])
    else:
        (trainImages, testImages, trainLabels, testLabels) = train_test_split(images, labels, test_size=0.25)

    print("[INFO] Fitting Model")
    optimizer = SGD(learning_rate=0.01, weight_decay=0.01/EPOCHS, momentum=0.9, nesterov=True)
    model = MiniVGGNet.build(128,  128, 3, num_classes=len(np.unique(imageLabels)))
    model.compile(loss="categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])
    model.fit(trainImages, trainLabels, batch_size=32, epochs=EPOCHS, verbose=1)
    print("[INFO] Model Fitting Complete")

    if trainOnly:
        print("[INFO] Testing Not Required. Proceeding To Response Preparation")
        testImages = trainImages
        testLabels = trainLabels
        # get predictions of the training set to use for the classification report
        predictions = model.predict(np.array( testImages ))
        uniqueLabels = np.unique(testLabels)

    else:
        print("[INFO] Preparing Testing Data")

        # Similar to the training set, load each image and perform a 
        # prediction on them to see what the model thinks it is
        # This prediction will be recorded for scoring later
        predictions = model.predict(testImages)
        uniqueLabels = np.unique(labels)

    print("[INFO] Scoring Model")
    # model.evaluate will return a list with two values:
    # first value: training loss
    # second value: training accuracy
    accuracy = model.evaluate(testImages, testLabels, batch_size=32)[1]
    classificationReport = classification_report(testLabels.argmax(axis=1), predictions.argmax(axis=1), target_names=uniqueLabels)
    print("[INFO] Train Request Complete, Returning Training Results")

    print("[INFO] Saving Trained Model")
    modelPath = os.path.join(PKL_PATH, str(taskId) + ".hdf5")
    model.save(modelPath)
    print("[INFO] Training Model Saved")

    response = MiniVGGTrainResponse(
        taskId=taskId,
        modelPath=modelPath,
        accuracy=accuracy,
        classificationReport=classificationReport
    )


    return response